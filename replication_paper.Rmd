---
title: 'Replication and Extension of "Why Friends and Neighbors? Explaining the Electoral Appeal of Local Roots"'
author: "Samuel Lowry"
date: "05/12/2020"
header-includes:
  \usepackage{caption}
  \captionsetup[figure]{labelformat=empty}
output: bookdown::pdf_document2
bibliography: bib.bib
biblio-style: "apalike"
fontsize: 12pt
linestretch: 1.5
toc: false
abstract: Campbell et al. (2019) which details two separate studies which bolster the cue based hypothesis of local roots. I successfully replicate all of their results. For my extension, with the first study, I used a Bayesian approach and found a negligible difference but did find heterogeneous effects based upon social class. With the second study, I looked at the interaction between the components and the respondent age groups as well as interaction between the components themselves where I found 18-24 year-olds being less critical of personal views influencing a member of Parliament's policy than their older counterparts and local roots downplaying the negative impact of the trustee model of representation on voter preference.
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(bookdown)
library(sandwich)
library(lmtest)
library(stargazer)
library(cowplot)
library(cobalt)
library(xtable)
library(devtools)
library(margins)
library(car)
library(foreign)
library(rms)
library(reshape2)
library(plyr)
library(arm)
library(huxtable)
library(factorEx)
library(dotwhisker)
library(rstanarm)
library(tidyverse)
```

```{r options}

#needed for correct huxtable output

options(huxtable.print = "latex")

#Seed set for entire document in honor of the class. 

set.seed(1006)
```

# Introduction {-} 

\textit{Why Friends and Neighbors? Explaining the Electoral Appeal of Local Roots} by Rosie Campbell, Philip Cowley, Nick Vivyan, and Markus Wagner in the \textit{The Journal of Politics} aims to answer the driving question of, "Why do politicians with strong local roots receive more electoral support?" by running and analyzing two separate studies. The first study uses a "paired profiles factorial vignette design" by asking respondents to rate pairs of hypothetical members of Parliament. The hypothetical members have varying levels of local roots as well as varying levels of "behavioral localism"—if they focus on local or national issues. In the second study,"a conjoint survey experiment," respondents again considered two hypothetical MPs with varying levels of local roots and behavioral localism but had to choose between them. A variable signaling if an MP was chosen or not was regressed against all of the components to determine their average marginal component effects (AMCE)—in other words, the change in probability of an MP being chosen. The first study followed their hypothesis that, "the effects of local roots on voter evaluations of politicians are reduced when voters receive direct information concerning behaviors about which they might otherwise use local roots as a cue." The second study, "showed that even if voters are provided with a rich array of information about politicians’ behavior and ideological positioning, the effect of local roots remained positive and notable," confirming the more simplistic first study.

Using R, I was able to replicate all of @paper. All of the code needed to do the same can be found within the Appendix. The original code can be found in the \textit{The Journal of Politics} Dataverse.^[https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/C15VOD] All of my code for this paper including the extension is available in my Github repository.^[https://github.com/SamuelLowry/why_friends_and_neighbors_replication_paper.git]

After being able to replicate all of the results from @paper. Next, in order to bolster their work and find interesting patterns nestled within the data, I delved into their models. With the first study, I used the Bayesian stan_glm instead of frequentist lm for the four models. Ultimately I found a negligible difference. I also looked at the heterogeneity of the treatment effect based upon social class. I found a notable difference between the unskilled working class and the other classes. With the second study, I looked at the interaction between the components and the respondent age groups where I found 18-24 year-olds being less critical of personal views influencing an MP's policy than their older counterparts. I also added an interaction term between local roots and policy influence to the model which aids the cue hypothesis in @paper.

# Literature Review {-} 

Due to @paper being a very recent article, published May 6, 2019, there has not been any follow-up scholarly work on the topic even from the authors themselves. Nevertheless, @paper builds off of a rich history of the "friends and neighbors" effect which was first coined by @key. Other notable works include @bowler and @garand which highlight the United States and @arzheimer as well as @arzheimer2 which highlight Britain. These two articles are particularly important due to @paper dealing with the "friends and neighbors" effect in the United Kingdom. These are just a couple of the notable works. Of course, more in way of an actual review is to come.

# Paper Review {-} 

@paper aims to answer the driving question of, "Why do politicians with strong local roots receive more electoral support?" by running and analyzing two separate studies. The first study uses a "paired profiles factorial vignette design" by asking respondents to rate pairs of hypothetical MP on a scale from 0-10. The hypothetical members, named Nick and Philip, have varying levels of local roots as well as varying levels of "behavioral localism"—if they focus on local or national issues. Philip's score was then subtracted from Nick's score, as Nick always had local roots. Nick's resulting relative score was then used as the dependent variable in the models. In the second study,"a conjoint survey experiment," respondents again considered two hypothetical MPs with varying levels of local roots and behavioral localism but had to choose between them. In this case, though, more components were added in order to see if something other than localism was at play. The total list includes party, level of local roots, days a week focused on constituency work, policy influence, and policy focus. A variable signaling if an MP was chosen or not was regressed against all of the components to determine their AMCE—in other words, the change in probability of an MP being chosen. A plethora of further information on conjoint analysis can be found in @con, but all in all it allows for the inference of causal relationships.

The first study followed their hypothesis that, "the effects of local roots on voter evaluations of politicians are reduced when voters receive direct information concerning behaviors about which they might otherwise use local roots as a cue." In other words, behavioral localism matters more to people than local roots. Therefore it takes precedent over local roots when it comes to voter preferences. Local roots is merely a cue. The second study, "showed that even if voters are provided with a rich array of information about politicians’ behavior and ideological positioning, the effect of local roots remained positive and notable," confirming the more simplistic first study. In addition, it showed a resounding preference for MPs being influenced by constituents over personal views.

# Replication {-} 

Using R, I was able to replicate all of @paper. All of the code needed to do the same can be found within the Appendix. The original code can be found in the \textit{The Journal of Politics} Dataverse.^[https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/C15VOD] All of my code for this paper including the extension is available in my Github repository.^[https://github.com/SamuelLowry/why_friends_and_neighbors_replication_paper.git]

# Extension {-} 

I was able to replicate all of the results from @paper. Next, in order to bolster their work and find interesting patterns nestled within the data, I delved into their models. Ultimately, I deemed the following four worthy enough to write about—two per study. 

Study 1

1. Using the Bayesian stan_glm instead of frequentist lm for the four models
2. Looking at the heterogeneity of the treatment effect based upon social class

Study 2

1. Looking at the interaction between the components and the respondent age groups
2. Adding an interaction term between local roots and policy influence to the model 

## Study 1 {-} 

```{r extensiondata}

#loaded in the data from the studies

d <- readRDS("paper_files/study1data.rds")

long.dat <- readRDS("paper_files/study2data_long.rds")
```

<left>

```{r study1table, fig.cap= "Bayesian Generalized Linear Models", warning=FALSE, message=FALSE, fig.align= "l"}

#recreated all of the models found in "Why Friends and Neighbors" but using stan_glm instead
#refresh is false to avoid the long output that comes with stan_glm normally. 

stan_m1 <- stan_glm(nickminusphil ~ localtreat*behtreatsimple,
                    data = d,
                    refresh = FALSE)

stan_m2 <- stan_glm(nickminusphil ~ localtreat*behtreatsimple + gender + agegrp + socgrade + qual,
                    data = d, 
                    refresh = FALSE)

stan_m3 <- stan_glm(nickminusphil ~ localtreat*behtreat, data = d, refresh = FALSE)

stan_m4 <- stan_glm(nickminusphil ~ localtreat*behtreat + gender + agegrp + socgrade + qual,
                    data = d, 
                    refresh = FALSE)

#huxtabe compiling all of the models
#Statistics and stars are null in order to avoid issues around significance as
#this is not a standard lm model.
#Errors on same level as coefficients in order to save space.
#Renamed all coefficients for presentability.

hux_1 <- huxreg(stan_m1, stan_m2, stan_m3, stan_m4,
                statistics = NULL,
                stars = NULL,
                error_pos = "same",
                note = "Table 1: Here stan_glm is used to construct the models instead of lm. The difference between the coefficients is negligible. The standard errors are slightly larger, though, due to stan_glm outputting MAD SD. The dependent variable is the relative rating of Nick compared to Philip.",
                coefs = c('Intercept' = '(Intercept)',
                          "Has Local Roots" = "localtreatLocal roots",
                          "Behavioral Info Given" = "behtreatsimpleBehavioural info",
                          "Treatment Interaction" = "localtreatLocal roots:behtreatsimpleBehavioural info",
                          "Male" = "genderMale",
                          "25-49" = "agegrp25-49",
                          "50-64" = "agegrp50-64",
                          "65+" = "agegrp65+",
                          "Skilled Working Class" = "socgradeC2",
                          "Lower Middle Class" = "socgradeC1",
                          "Middle Class" = "socgradeAB",
                          "GCSE" = "qualLevel 1/2",
                          "A Levels" = "qualLevel 3",
                          "University" = "qualLevel 4",
                          "Constituency Focus" = "behtreatConst. focus",
                          "National Focus" = "behtreatWestmin. focus",
                          "Local:Constituency" = "localtreatLocal roots:behtreatConst. focus",
                          "Local:National" = "localtreatLocal roots:behtreatWestmin. focus"))

#Printing huxtable with caption and defined width

hux_1 <- hux_1 %>%
  set_caption('Bayesian Generalized Linear Models Instead of Linear Models')

width(hux_1) <- 1

hux_1

```


</left>

In Table 1, the four models from the first study were created using the Bayesian stan_glm function from the rstanarm package^[https://cran.r-project.org/web/packages/rstanarm/index.html] instead of the traditional, frequentist lm function used in @paper. Stan_glm allows for the use or priors, but in this case they are not used. While stan_glm uses a Gaussian process in order to construct its models, due to not including a prior, the difference between the coefficients is practically nonexistent.^[Compare Table 1 to Table 2 in the Appendix] There is a difference, though, between the standard errors. @paper uses "robust standard errors". In this case, they used the vcovHC function from the sandwich package^[https://cran.r-project.org/web/packages/sandwich/sandwich.pdf]. VcovHC calculates heteroscedasticity consistent standard errors. As described in @hetero, "heteroscedasticity occurs when the variance of the errors varies across observations." In an ordinary least squares regression, this can lead to bias due to differing variance across different groups. VcocHC seeks to account for this difference leading to "robust", unbiased standard errors. Stan_glm on the other hand outputs median absolute deviation (MAD SD) in the standard error parentheses. In order to get the MAD SD, the median absolute deviation is scaled by 1.483 which, according to @textbook, "reproduces the standard error in the special case of a the normal distribution". @textbook describes MAD SD as a, "more stable measure of variation".^[See page 67 of @textbook for more details] In both cases, the standard errors are more robust than the traditional standard error. Nevertheless, the MAD SD tends to be larger than the robust standard error used in @paper. All in all, the difference between the use of lm and stan_glm in this case is largely negligible.

<left>

```{r study1figure, fig.cap="Figure 1: Stan_glm model of the interaction between the treatment effects by social class. The lines denote 95% credible intervals. The treatments affect the unskilled working class in a notably different manner."}

#Subsetting based upon class

d_d <- d %>% filter(socgrade == "DE")

d_c2 <- d %>% filter(socgrade == "C2")

d_c1 <- d %>% filter(socgrade == "C1")

d_a <- d %>% filter(socgrade == "AB")

#creating model from treatment variable with interaction based upon each class.

stan_d <- stan_glm(nickminusphil ~ localtreat*behtreat,
                    data = d_d, 
                    refresh = FALSE)

stan_c2 <- stan_glm(nickminusphil ~ localtreat*behtreat,
                    data = d_c2, 
                    refresh = FALSE)

stan_c1 <- stan_glm(nickminusphil ~ localtreat*behtreat,
                    data = d_c1, 
                    refresh = FALSE)

stan_a <- stan_glm(nickminusphil ~ localtreat*behtreat,
                    data = d_a, 
                    refresh = FALSE)

#dot whisker plots in order to show coefficients. 
#dodge size in order to better separate models on chart for readablility.
#Relabled coefficients. 
#added line at 0 to better show sign of coefficient
#Adjusting legend for readability and position.
#Labeled appropriatley

dwplot(list(stan_a, stan_c1, stan_c2, stan_d),
       dodge_size = .6) %>% 
  relabel_predictors(c("(Intercept)" = "Intercept",                   
                     "localtreatLocal roots" = "Local Roots (Baseline = None) \nLocal Roots",          
                     "behtreatConst. focus" = "Behavioral Information (Baseline = None) \nConstituency Focus",
                     "behtreatWestmin. focus" = "National Focus",
                     "localtreatLocal roots:behtreatConst. focus" = "Interaction Terms \nLocal:Constituency Focus",
                     "localtreatLocal roots:behtreatWestmin. focus" = "Local:National Focus")) + 
  geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
  scale_colour_hue(name = "Social Class",
                     labels = c("Middle", "Lower Middle", "Skilled Working", "Unskilled Working")) +
  theme(legend.text = element_text(size = 6),
        legend.title = element_text(size = 8),
        legend.position = c(.163, .81)) +
  labs(title = "Treatment Coefficients Across Social Classes",
       x = "Coefficient Value")

```

</left>

In Figure 1, stan_glm was used to create four models from subsets of the data based upon the NRS social grade of the respondents^[AB = Middle, C1 = Lower Middle, C2 = Skilled Working, DE = Unskilled Working] in order to discover heterogeneous effects. The unskilled working class stands out from the rest. The local roots treatment does not definitively positively impact their rating of Nick unlike the other classes. In addition, while the other classes are not definitively deterred by behavior indicative of a national focus, the unskilled working class is. Nevertheless, the median constituency focus coefficient is notably lower for the unskilled working class than the other classes. Thus, the unskilled working class more so rejects a focus on national polices than endorses a focus on local politics compared to the other classes. The interaction terms are also different. For both the local roots constituency focus group and the local roots national focus group the slope is larger for the unskilled working class unlike the other classes—granted, the 95% credible just peeks over zero for some of the other classes.^[See page 128-129 of @textbook for further information on interaction] The treatment effects are notably different by class. 


## Study 2 {-} 

<left>

```{r study2hetero, fig.cap="Figure 2: The average marginal component effects from the second study depicted amongst subsets of respondent age. Lines denote a 95% confidence interval. There is a notable difference amongst 18-24 year-olds in regards to personal views influencing an MP's policies."}

#subsetting based upon age. 

long.dat_18 <- long.dat %>% filter(age_grouped == "18-24")

long.dat_25 <- long.dat %>% filter(age_grouped == "25-39")

long.dat_40 <- long.dat %>% filter(age_grouped == "40-59")

long.dat_60 <- long.dat %>% filter(age_grouped == "60+")

#conjoint models for each of the subsets 

conjoint_18 <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender, data = long.dat_18)

conjoint_25 <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender, data = long.dat_25)

conjoint_40 <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender, data = long.dat_40)

conjoint_60 <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender, data = long.dat_60)

#dot whisker plot showing the coefficients 
#dodge size in order to better separate models on chart for readablility.
#Relabled coefficients. 
#added line at 0 to better show sign of coefficient
#Adjusting legend for readability and position.
#Labeled appropriatley

dwplot(list(conjoint_18, conjoint_25, conjoint_40, conjoint_60),
       dodge_size = .6) %>% 
  relabel_predictors(c("(Intercept)" = "Intercept",                   
                     "mp.partyposLabour centre" = "Party (Baseline = Labour Left-wing) \nLabour Centre",          
                     "mp.partyposConservative centre" = "Conservative Centre",
                     "mp.partyposConservative right-wing" = "Conservative Right-wing",
                     "mp.localroots5 years in area" = "Local Roots (Baseline = Lives Elsewhere) \n5 Years in Area",
                     "mp.localroots20 years in area" = "20 years in area",
                     "mp.localrootsGrew up and lives in area" = "Grew up and Lives in Area",
                     "mp.const2 days" = "Constituency Work (Baseline = 1 Day) \n 2 days",
                     "mp.const3 days" = "3 Days",
                     "mp.const4 days" = "4 Days",
                     "mp.influenceConstituents" = "Policy Influence (Baseline = Party) \nConstituents' Views",
                     "mp.influenceOwn personal" = "Own Personal Views",
                     "mp.policyEducation and health" = "Policy Focus (Baseline = Economy and Tax) \nEducation and Health",
                     "mp.genderMale" = "Sex (Baseline = Female) \nMale")) + 
  geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
  scale_colour_hue(name = "Age Group",
                     labels = c("18-24", "25-39", "40-59", "60+")) +
  theme(legend.position = c(.155, .5)) +
  labs(title = "Average Marginal Component Effects \nby Age Group",
       x = "Change in Probability of MP Being Preferred")

```

</left>

In Figure 2, the AMCE from the second study are depicted amongst subsets of respondent age. @con, the landmark paper on conjoint analysis, outlines two types of interaction within conjoint studies. The first involves two components interacting. The second involves a component interacting with respondent attributes. Here, the latter is occurring, as seen by the notable difference between the age groups in the component effect of personal views being a policy influence. For all age groups except 18-24 year-olds, the AMCE is negative—granted, the 95% confidence interval crosses zero for both 40-59 year-olds and the 60+ group. The 18-24 year-old respondents were definitively swayed in their selection an MP by personal views having an influence on the MP's politics, as the 95% confidence interval does not cross zero. This is especially interesting because policy influence between personal views and constituents' views elicits the greatest difference amongst the AMCE when all respondents are analysed together.^[See Figure 3]  

<left>

```{r study2interaction, fig.height = 6, fig.cap="Figure 3: The average marginal component effects from the second study with and without interaction between local roots and policy influence. Lines denote a 95% confindence interval. The average component interaction effects demonstrate how local roots can downplay the negative impact of personal views influencing policy."}

#recreation of AMCE from the paper.

conjoint <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender, data = long.dat)


#added an interesting interaction term This is interesting because is shows that
#we see less care about policy influence with increase in local roots

conjoint_interaction <- lm(formula = mp.preferred ~ mp.partypos + mp.localroots + mp.const + mp.influence + mp.policy + mp.gender + mp.localroots:mp.influence,
                           data = long.dat)

#grew up significant at 95% confidence for both interaction terms

#dot whisker plot showing the coefficients 
#Relabled coefficients. 
#added line at 0 to better show sign of coefficient
#Adjusting legend for readability and position.
#Labeled appropriatley

dwplot(list(conjoint, conjoint_interaction)) %>% 
   relabel_predictors(c("(Intercept)" = "Intercept",                   
                     "mp.partyposLabour centre" = "Party (Baseline = Labour Left-wing) \nLabour Centre",          
                     "mp.partyposConservative centre" = "Conservative Centre",
                     "mp.partyposConservative right-wing" = "Conservative Right-wing",
                     "mp.localroots5 years in area" = "Local Roots (Baseline = Lives Elsewhere) \n5 Years in Area",
                     "mp.localroots20 years in area" = "20 years in area",
                     "mp.localrootsGrew up and lives in area" = "Grew up and Lives in Area",
                     "mp.const2 days" = "Constituency Work (Baseline = 1 Day) \n 2 days",
                     "mp.const3 days" = "3 Days",
                     "mp.const4 days" = "4 Days",
                     "mp.influenceConstituents" = "Policy Influence (Baseline = Party) \nConstituents' Views",
                     "mp.influenceOwn personal" = "Own Personal Views",
                     "mp.policyEducation and health" = "Policy Focus (Baseline = Economy and Tax) \nEducation and Health",
                     "mp.genderMale" = "Sex (Baseline = Female) \nMale",
                     "mp.localroots5 years in area:mp.influenceConstituents" = "Interaction Terms \n5 Years:Constituents' Views",
                     "mp.localroots20 years in area:mp.influenceConstituents" = "20 Years:Constituents' Views",
                     "mp.localrootsGrew up and lives in area:mp.influenceConstituents" = "Grew up:Constituents' Views",
                     "mp.localroots5 years in area:mp.influenceOwn personal" = "5 Years:Own Personal",
                     "mp.localroots20 years in area:mp.influenceOwn personal" = "20 Years:Own Personal",
                     "mp.localrootsGrew up and lives in area:mp.influenceOwn personal" = "Grew up:Own Personal")) +
  geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
  scale_colour_hue(name = "AMCE Type",
                     labels = c("Without \nInteraction Terms", "With \nInteraction Terms")) +
  theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.position = c(.19, .7)) +
  labs(title = "Average Marginal Component Effects \nwith Interaction",
       x = "Change in Probability of MP Being Preferred")
```

</left>

In Figure 3, the average component interaction effects (ACIE) between local roots and policy influence are shown in addition to the AMCE depicted in @paper. In regards to @con, the first type of interaction is seen here. The ACIE display how local roots in part negate the negative effect of personal views influencing policy. The interaction term for the MPs that grew up and live in the area and that allow constituents to influence policy and the interaction term for MPs that grew up and live in the area and that allow their own personal views influence policy are both positive and significant at a 95% confidence level. In other words, local roots, the subject of @paper, excuses what is otherwise seen as undesirable. Nevertheless, it may not be a case of excusing what respondents otherwise see as bad. Instead, respondents could claim that they trust an MP's personal views more if they are from the same area. 

# Conclusion {-} 

In conclusion, I was able to replicate all of @paper. Then I delved into their models. The use of stan_glm instead of lm within the first study is largely negligible. The heterogeneity of the treatment effect based upon social class, on the other hand, exposed a firm rejection of the trustee model by the unskilled working class. It also depicted their difference in regards to the interaction terms. With the second study, the interaction between the components and the respondent age groups exposed the fact that 18-24 year-olds are less critical of personal views influencing an MP's policy than their older counterparts. In addition, the interaction term between local roots and policy influence supports the cue hypothesis from @paper. Even when an MP was serving in a trustee model, that was slightly overlooked due to local roots. It is quite possible that local roots acted as a cue to the respondents allowing them to be more likely to trust MPs whose policy is influenced by their own views. 

Ultimately, my extension of @paper does not contradict their findings but instead bolsters them. Granted, it did find some heterogeneous effects. Thus, we rely on local roots when other information is missing, or we view it as a lens which can excuse the trustee model of representation. @paper focuses mostly upon behavioral localism and not the motivation behind that behavior. Therefore, more research could be done in order to determine the relationship between the trustee model of representation and local roots.  

\newpage

# References {-} 

<div id="refs"></div>

\newpage

# (APPENDIX) Appendix {-} 

# Appendix of Replicated Graphics {-} 

I was able to replicate Table 2, Figure 1, and Figure 3 from @paper. I was unable to replicate Table 1 and Figure 2 because they were not data related. They were merely visualizations displaying content about methods and experimental design. Table 1 depicts written descriptions of the hypothetical MPs present to subject. Figure 2 depicts a screenshot of the survey. The replicated table and figures are below.

## Table 2 {-} 

```{r appendixdata}
#loaded in the data from the first study

d <- readRDS("paper_files/study1data.rds")

```

```{r appendixtable2, warning=FALSE,out.height=6, results='asis'}
#warning = FALSE in order to get rid of unknown variable due to their code being wacl

#models for this graphic and the table later on

#the standard error calculations are for their robust standard errors

m1 <- lm(nickminusphil ~ localtreat*behtreatsimple, data = d)
se1 <- sqrt(diag(vcovHC(m1)))

m2 <- lm(nickminusphil ~ localtreat*behtreatsimple +
           gender + agegrp + socgrade + qual
         , data = d)
se2 <- sqrt(diag(vcovHC(m2)))

m3 <- lm(nickminusphil ~ localtreat*behtreat, data = d)
se3 <- sqrt(diag(vcovHC(m3)))

m4 <- lm(nickminusphil ~ localtreat*behtreat +
           gender + agegrp + socgrade + qual
         , data = d)
se4 <- sqrt(diag(vcovHC(m4)))

#I took the code for table 2 from their code and made it output to Latex

stargazer(mget(paste0("m",1:4)),
          se = mget(paste0("se",1:4)),
          type = "latex",
          float = FALSE,
          dep.var.caption = "",
          dep.var.labels.include = FALSE,
          title = "",
          header = FALSE,
          #intercept.bottom = FALSE, intercept.top = TRUE,
          keep.stat = c("n", "rsq", "adj.rsq"),
          no.space = TRUE, 
          omit = "socgrade|agegrp|gender|qual",
          order = c("Constant", "^localtreatLocal roots$", 
                    "^behtreatsimpleBehavioural info$", 
                    "^behtreatConst. focus$", 
                    "^behtreatWestmin. focus$",
                    "^localtreatLocal roots:behtreatsimpleBehavioural info$",
                    "^localtreatLocal roots:behtreatConst. focus$",
                    "^localtreatLocal roots:behtreatWestmin. focus$"
          ),
          add.lines = list(c("Controls for voter characteristics?", 
                             rep(c("No","Yes"), 2))),
          covariate.labels = c("Intercept", "Local roots", "Behavioral localism information",
                               "Behavioral localism: High (vs. no info)",
                               "Behavioral localism: Low (vs. no info)",
                               "Local roots X Behavioral info.", 
                               "Local roots X High behavioral localism",
                               "Local roots X Low behavioral localism"))
```

Caption from @paper: "All models estimated via ordinary least squares. Dependent variable is respondent relative rating of MP Nick (the 0–10 rating of Nick minus that of Philip). Robust standard errors in parentheses. N = 5,203."

### Figure 1 {-}

```{r appendixfigure1, warning = FALSE, cache = TRUE, fig.cap="Figure 1. Effects of local roots conditional on behavioral information treatments (study 1). A, Predicted relative rating of MP Nick (MP Nick rating minus MP Philip rating) as the MP local roots treatment varies, with all control variables held constant at their modal value in the sample. Top, predicted values when respondents receive no information about MP behavioral localism. Middle, predicted values when respondents receive information about MP behavioral localism and Nick is revealed to be low in behavioral localism. Bottom, predicted values when respondents receive information about MP behavioral localism and Nick is revealed to be high in behavioral localism. For each of the same behavioral localism conditions, B show the estimated treatment effect of MP Nick having local roots. Estimates are calculated from model 4 in table 2. Open circles indicate point estimates. Lines denote 95% confidence intervals."}

#warning is false to delete warning for unknown variable specified in code which does not change vizualization from the paper. 

#function needed for figure 1

predict.rob <- function(object, vcov,newdata){
  tt <- terms(object)
  if(missing(newdata)){ newdata <- x$model }
  else {
    Terms <- delete.response(tt)
    m <- model.frame(Terms, newdata, na.action = na.pass, 
                     xlev = object$xlevels)
    if (!is.null(cl <- attr(Terms, "dataClasses"))) 
      .checkMFClasses(cl, m)
    X <- model.matrix(Terms, m, contrasts.arg = object$contrasts)
    offset <- rep(0, nrow(X))
    if (!is.null(off.num <- attr(tt, "offset"))) 
      for (i in off.num) offset <- offset + eval(attr(tt, 
                                                      "variables")[[i + 1]], newdata)
    if (!is.null(object$call$offset)) 
      offset <- offset + eval(object$call$offset, newdata)
    mmDone <- FALSE
  }
  #m.mat <- model.matrix(x$terms,data=newdata)
  m.coef <- object$coef
  fit <- as.vector(X %*% object$coef)
  se.fit <- sqrt(diag(X%*%vcov%*%t(X)))
  return(list(fit=fit,se.fit=se.fit))
}


### Figure 1
## Avg treatment effect of local roots with const and westmihn. info
out <- summary(margins(m4, vcov = vcovHC(m4), 
                       at = list(behtreat = c("No behavioural info", "Const. focus", "Westmin. focus"))))
out <- subset(out, factor == "localtreatLocal roots")
margins.m4 <- out 

## make margins plot
margins.comb <- margins.m4
margins.comb$behtreat.neat <- car:::recode(margins.comb$behtreat, 
                                           '"No behavioural info" = "Behavioral information treatment --\\nNo information (Vignettes 1-2)";
                                           "Westmin. focus" = "Behavioral information treatment --\\nLow behavioral localism (Vignettes 5-6)";
                                           "Const. focus" = "Behavioral information treatment --\\nHigh behavioral localism (Vignettes 3-4)"')
margins.comb$behtreat.neat <- factor(sub(" --", ":", margins.comb$behtreat.neat),
                                     levels = c("Behavioral information treatment:\nNo information (Vignettes 1-2)", 
                                                "Behavioral information treatment:\nLow behavioral localism (Vignettes 5-6)",
                                                "Behavioral information treatment:\nHigh behavioral localism (Vignettes 3-4)"
                                     ))
p1 <- ggplot(margins.comb, aes(x = factor, y = AME)) + 
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  geom_linerange(aes(x=factor, xend=factor, ymin=lower, ymax=upper), size = 0.6) +
  geom_point(size = 3.5, shape = 21, fill = "white") +
  labs(x = "", y = "") + 
  coord_flip() +
  facet_wrap( ~ behtreat.neat, ncol = 1) + 
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + 
  ggtitle("(b) Effect of MP local\ntreatment") 




## predlevels for m4
newdf <- data.frame(expand.grid(localtreat = factor(c("No local roots", "Local roots"), 
                                                    levels = levels(d$localtreat)),
                                behtreat = factor(levels(d$behtreat), levels = levels(d$behtreat))
),
gender = factor(levels(d$gender)[which.max(table(d$gender))], 
                levels = levels(d$gender)),
agegrp = factor(levels(d$agegrp)[which.max(table(d$agegrp))], 
                levels = levels(d$agegrp)),
socgrade = factor(levels(d$socgrade)[which.max(table(d$socgrade))], 
                  levels = levels(d$socgrade)),
qual = factor(levels(d$qual)[which.max(table(d$qual))], 
              levels = levels(d$qual))
)
preds <- predict.rob(m4, vcov = vcovHC(m4), newdata = newdf)
newdf$yhat <- preds$fit
newdf$se.yhat <- preds$se.fit
newdf$lo <- newdf$yhat - (1.96*newdf$se.yhat)
newdf$hi <- newdf$yhat + (1.96*newdf$se.yhat)
predlevels.m4 <- newdf


## make predlevels plot
predlevels.comb <- predlevels.m4
predlevels.comb$behtreat.neat <- car:::recode(predlevels.comb$behtreat, 
                                              '"No behavioural info" = "Behavioral information treatment --\\nNo information (Vignettes 1-2)";
                                              "Westmin. focus" = "Behavioral information treatment --\\nLow behavioral localism (Vignettes 5-6)";
                                              "Const. focus" = "Behavioral information treatment --\\nHigh behavioral localism (Vignettes 3-4)"')
predlevels.comb$behtreat.neat <- factor(sub(" --", ":", predlevels.comb$behtreat.neat),
                                        levels = c("Behavioral information treatment:\nNo information (Vignettes 1-2)", 
                                                   "Behavioral information treatment:\nLow behavioral localism (Vignettes 5-6)",
                                                   "Behavioral information treatment:\nHigh behavioral localism (Vignettes 3-4)"
                                        ))

p2 <- ggplot(predlevels.comb, aes(x = localtreat, y = yhat)) + 
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  geom_linerange(aes(x=localtreat, xend=localtreat, ymin=lo, ymax=hi), size = 0.6) +
  geom_point(size = 3.5, shape = 21, fill = "white") +
  labs(x = "", y = "") + 
  coord_flip() +
  facet_wrap( ~ behtreat.neat, ncol = 1) + 
  theme_bw() +
  theme(legend.position = "bottom") + 
  ggtitle("(a) Predicted relative rating")



## Now combine aspects of above plots into 3 x 2 plot
pcomb <- plot_grid(p2, p1, align = "h", rel_widths = c(1,0.8))

pcomb
```

\newpage

### Figure 3 {-}

```{r appendixfigure3, warning = FALSE, fig.cap="Figure 3. Estimated average marginal component effects of each MP attribute level compared to the baseline level of the attribute, estimated via ordinary least squares regression, with standard errors clustered by respondent. Bars show 95% confidence intervals"}

#warning is false to delete warning for 11 deletions caused by ggplot which does not change vizualization from the paper. 

#needed data

long.dat <- readRDS(file = "paper_files/study2data_long.rds")

### Create labels for plotting

# for full results
labels.full <- rev(expression(
  "", italic("Party & position (baseline = Labour left-wing)"), "Labour centre", "Conservative centre", "Conservative right-wing",
  "", italic("Local roots (baseline = lives elsewhere)"),"5 years in area", "20 years in area", "Grew up and lives in area", 
  "", italic("Constituency work (baseline = 1 day)"), "2 days", "3 days", "4 days",
  "", italic("Main policy influence (baseline = party)"), "constituents' views","own personal views",
  "", italic("Policy interests (baseline = economy and tax)"), "education and health",
  "", italic("MP sex (baseline = female)"), "male"))

# for x axis
effect.label <- "Change in probability of MP being\npreferred relative to baseline"

#needed functions

add.top <- function(df, new.level){
  to.add <- data.frame(mean = c(NA,NA, 0), ci.lo = c(NA,NA, 0), ci.hi = c(NA,NA, 0),
                       category = rep("", 3), attribute = rep(df$attribute[1],3),
                       level = c("", " ", new.level))
  return(rbind(to.add, df))
}
add.justify <- function(df){
  df$left.justify <- rep(0, nrow(df))
  df$left.justify[2] <- 1
  return(df)
}

## Function to get regression-based AMCE estimates for each attribute level using 
## OLS estimator with clustered SEs (Hainmueller, Hopkins and Yammamoto 2014)

#Note to read up on the other literature above

get.amcetab <- function(data, variables, J = 2){    
  Nvar <- length(variables)
  amce.list <- vector("list", length = Nvar)
  
  for(i in 1:Nvar){ # get AMCE for each variable attribute
    fmla <- as.formula(paste("mp.preferred ~ ",variables[i], sep = ""))
    model <- ols(fmla, data = data, x = T, y = T) 
    # NOTE: The data for the model has to have no NAs on any model variables 
    # for the robcov(cluster()) function to work 
    model.clus <- robcov(model, cluster = data$ID, method = "efron")
    coef <- model.clus$coef[names(model.clus$coef)!="Intercept"]
    se.clus <- sqrt(diag(model.clus$var))
    se.clus <- se.clus[names(se.clus)!="Intercept"]       
    sub.tab <- data.frame("AMCE" = coef, 
                          "ci.lo" = coef - (1.96*se.clus),
                          "ci.hi" = coef + (1.96*se.clus),
                          "cluster.se" = se.clus)
    sub.tab$category <- names(coef)
    sub.tab <- cbind(sub.tab, colsplit(sub.tab$category, "=", c("attribute","level")))
    sub.tab$level <- as.character(sub.tab$level)    
    row.names(sub.tab) <- NULL
    # add in gaps and baselines
    to.add <- data.frame(AMCE = c(NA,NA, 0), ci.lo = c(NA,NA, 0), ci.hi = c(NA,NA, 0),
                         cluster.se = c(NA,NA, 0),
                         category = rep("", 3), attribute = rep(sub.tab$attribute[1],3),
                         level = c("", " ", "baseline"))
    amce.list [[i]] <- rbind(to.add, sub.tab)
  } 
  amce.tab <- do.call("rbind", amce.list)
  # re-make initial labels column
  amce.tab$category <- paste(amce.tab$attribute, amce.tab$level, sep = ": ")
  # make this into ordered factor
  amce.tab$category <- factor(amce.tab$category, levels = rev(amce.tab$category), order =T)    
  
  return(amce.tab)
}

## Function that calls get.amcetab for multiple predictors and combines results

amce.tab <- function(data, variables, multi = F, same.party = F){
  # data must be a single data frame or a list of data frames (if multi = T)
  # with named elements
  # Also relies on specific ordering of explanatory variables
  if(multi == T & same.party == F){
    amce.tab.list <- list(NA, length = length(data))
    for(i in 1:length(data)){
      tmp <- get.amcetab(data[[i]], variables = variables)
      tmp$set <- rep(names(data)[i], nrow(tmp))
      amce.tab.list[[i]] <- tmp
    }
    amce.tab <- do.call("rbind",amce.tab.list)
    amce.tab$set <- factor(amce.tab$set)
    return(amce.tab)
  }
  if(multi == T & same.party == T){
    amce.tab.list <- list(NA, length = length(data))
    for(i in 1:length(data)){
      vars <- if(grepl("same party", names(data)[i])==T|grepl("Same Party", names(data)[i])==T) variables[2:length(variables)] else variables
      tmp <- get.amcetab(data[[i]], variables = vars)
      tmp$set <- rep(names(data)[i], nrow(tmp))
      amce.tab.list[[i]] <- tmp
    }
    names(amce.tab.list) <- names(data)
    diff.party <- amce.tab.list[grepl("same party", names(amce.tab.list))==F&
                                  grepl("Same Party", names(amce.tab.list))==F]
    same.party <- amce.tab.list[grepl("same party", names(amce.tab.list))==T |
                                  grepl("Same Party", names(amce.tab.list))==T]
    to.add <- data.frame(AMCE = rep(NA, 4), ci.lo = rep(NA, 4), ci.hi =  rep(NA, 4),
                         cluster.se =  rep(NA, 4),
                         category =  diff.party[[1]]$category[1:4], 
                         attribute =  diff.party[[1]]$attribute[1:4], 
                         level = diff.party[[1]]$level[1:4],
                         set = rep(NA, 4))
    for(i in 1:length(data)){                     
      if(grepl("same party", names(data)[i])==T|grepl("Same Party", names(data)[i])==T){
        amce.tab.list[[i]] <- rbind(to.add,amce.tab.list[[i]])
        amce.tab.list[[i]]$set[1:4] <-  amce.tab.list[[i]]$set[5:8]
      }
      else amce.tab.list[[i]] <- amce.tab.list[[i]]
    }     
    amce.tab <- do.call("rbind",amce.tab.list)
    amce.tab$set <- factor(amce.tab$set)
    return(amce.tab)
  } 
  if(multi == F)   {
    get.amcetab(data, variables)
  }
  
}


### Figure 3: AMCEs for all attributes

res <- amce.tab(data = long.dat, 
                variables = c("mp.partypos", "mp.localroots", "mp.const", "mp.influence", "mp.policy", "mp.gender"),
                multi = F)
res$category <- factor(as.character(res$category), levels = rev(as.character(res$category)), order =T)
#write.csv(res, "amce-all.csv")# write results to csv file

# Full plot for all attributes
res <- res[2:nrow(res),] # chop off top empty layer
res <- subset(res, level != "baseline")# remove artificial 'baseline' rows
labels <- labels.full
ggplot(res, aes(x = category, y = AMCE, color = attribute)) + 
  geom_hline(yintercept = 0, linetype = "dashed", size = 0.5) +
  geom_pointrange(aes(ymin = ci.lo, ymax = ci.hi), size = 0.75) + 
  labs(y = effect.label, x = "") + 
  coord_flip() + 
  theme_bw() + 
  theme(axis.text = element_text(colour = "black")) +
  theme(legend.position = "none") +
  theme(text = element_text(size = 15)) +
  theme(axis.ticks.y = element_blank(), axis.text.y = element_text(hjust = 1), # remove ticks and justify
        axis.title.x = element_text(size = 13, vjust = 0)) + 
  scale_x_discrete(labels=labels)

```
